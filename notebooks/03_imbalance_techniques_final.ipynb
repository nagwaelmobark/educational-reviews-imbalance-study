{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9SGoBNmCL6fkSsjc1Hkir",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagwaelmobark/educational-reviews-imbalance-study/blob/main/notebooks/03_imbalance_techniques_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XxkBueLDSEy",
        "outputId": "ef73884d-3f44-4cdf-9701-9aeb66a6b212"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç DEBUG MODE - Step by Step Analysis\n",
            "==================================================\n",
            "‚úÖ Data loaded: 107,018 reviews\n",
            "‚úÖ Features: (85614, 5000)\n",
            "\n",
            "üìä Class Distribution:\n",
            "Rating 1: 1,975 (2.3%)\n",
            "Rating 2: 1,801 (2.1%)\n",
            "Rating 3: 4,057 (4.7%)\n",
            "Rating 4: 14,443 (16.9%)\n",
            "Rating 5: 63,338 (74.0%)\n",
            "\n",
            "üî¨ BASELINE TEST...\n",
            "Baseline Macro F1: 0.3691\n",
            "Baseline Accuracy: 0.7653\n",
            "\n",
            "Baseline per-class F1:\n",
            "  Rating 1: 0.4187\n",
            "  Rating 2: 0.1433\n",
            "  Rating 3: 0.1881\n",
            "  Rating 4: 0.2151\n",
            "  Rating 5: 0.8804\n",
            "\n",
            "üß™ TEST 1: Class-Weighted SVM...\n",
            "Class weights calculated:\n",
            "  Rating 1: 8.67\n",
            "  Rating 2: 9.51\n",
            "  Rating 3: 4.22\n",
            "  Rating 4: 1.19\n",
            "  Rating 5: 0.27\n",
            "‚úÖ Weighted SVM Macro F1: 0.3651\n",
            "‚úÖ Improvement: -1.1%\n",
            "\n",
            "Weighted SVM per-class F1:\n",
            "  Rating 1: 0.3088 (-26.2%)\n",
            "  Rating 2: 0.1647 (+14.9%)\n",
            "  Rating 3: 0.2280 (+21.2%)\n",
            "  Rating 4: 0.3309 (+53.8%)\n",
            "  Rating 5: 0.7931 (-9.9%)\n",
            "\n",
            "üß™ TEST 2: Weighted Logistic Regression...\n",
            "‚úÖ Weighted Logistic Macro F1: 0.4087\n",
            "‚úÖ Improvement: +10.7%\n",
            "\n",
            "Weighted Logistic per-class F1:\n",
            "  Rating 1: 0.3774 (-9.9%)\n",
            "  Rating 2: 0.1997 (+39.3%)\n",
            "  Rating 3: 0.2651 (+40.9%)\n",
            "  Rating 4: 0.3221 (+49.7%)\n",
            "  Rating 5: 0.8794 (-0.1%)\n",
            "\n",
            "üß™ TEST 3: Weighted Random Forest...\n",
            "‚úÖ Weighted RF Macro F1: 0.2716\n",
            "‚úÖ Improvement: -26.4%\n",
            "\n",
            "Weighted RF per-class F1:\n",
            "  Rating 1: 0.2331 (-44.3%)\n",
            "  Rating 2: 0.0371 (-74.1%)\n",
            "  Rating 3: 0.0486 (-74.1%)\n",
            "  Rating 4: 0.1888 (-12.2%)\n",
            "  Rating 5: 0.8502 (-3.4%)\n",
            "\n",
            "üß™ TEST 4: Simple Oversampling...\n",
            "Original training size: 85,614\n",
            "Oversampled training size: 104,494\n",
            "New distribution:\n",
            "  Rating 1: 11,850 (11.3%)\n",
            "  Rating 2: 10,806 (10.3%)\n",
            "  Rating 3: 4,057 (3.9%)\n",
            "  Rating 4: 14,443 (13.8%)\n",
            "  Rating 5: 63,338 (60.6%)\n",
            "‚úÖ Oversampled SVM Macro F1: 0.3486\n",
            "‚úÖ Improvement: -5.5%\n",
            "\n",
            "Oversampled SVM per-class F1:\n",
            "  Rating 1: 0.3497 (-16.5%)\n",
            "  Rating 2: 0.2189 (+52.7%)\n",
            "  Rating 3: 0.0919 (-51.1%)\n",
            "  Rating 4: 0.1972 (-8.3%)\n",
            "  Rating 5: 0.8855 (+0.6%)\n",
            "\n",
            "üìä SUMMARY OF ALL TECHNIQUES:\n",
            "========================================\n",
            "üèÜ BEST TECHNIQUE: Weighted Logistic\n",
            "üìà Best Macro F1: 0.4087\n",
            "üìà Improvement over baseline: +10.7%\n",
            "\n",
            "üéØ All Results:\n",
            "  Baseline SVM: 0.3691 (+0.0%)\n",
            "  Weighted SVM: 0.3651 (-1.1%)\n",
            "  Weighted Logistic: 0.4087 (+10.7%)\n",
            "  Weighted Random Forest: 0.2716 (-26.4%)\n",
            "  Oversampled SVM: 0.3486 (-5.5%)\n",
            "\n",
            "‚úÖ DEBUG COMPLETE!\n",
            "üí° SUCCESS: Found improvement with Weighted Logistic!\n"
          ]
        }
      ],
      "source": [
        "# Debug Version - Let's see what's happening step by step\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "print(\"üîç DEBUG MODE - Step by Step Analysis\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Load data\n",
        "!wget -q https://raw.githubusercontent.com/nagwaelmobark/educational-reviews-imbalance-study/main/data/raw/reviews.csv\n",
        "df = pd.read_csv('reviews.csv')\n",
        "\n",
        "# Quick preprocessing\n",
        "df = df.dropna(subset=['Review', 'Label'])\n",
        "df['Review_cleaned'] = df['Review'].astype(str).str.lower()\n",
        "\n",
        "print(f\"‚úÖ Data loaded: {len(df):,} reviews\")\n",
        "\n",
        "# Train-test split\n",
        "X = df['Review_cleaned']\n",
        "y = df['Label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Feature extraction\n",
        "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"‚úÖ Features: {X_train_tfidf.shape}\")\n",
        "\n",
        "# Check class distribution\n",
        "print(f\"\\nüìä Class Distribution:\")\n",
        "class_counts = y_train.value_counts().sort_index()\n",
        "for rating, count in class_counts.items():\n",
        "    percentage = (count / len(y_train)) * 100\n",
        "    print(f\"Rating {rating}: {count:,} ({percentage:.1f}%)\")\n",
        "\n",
        "# =============================================================================\n",
        "# BASELINE TEST\n",
        "# =============================================================================\n",
        "\n",
        "print(f\"\\nüî¨ BASELINE TEST...\")\n",
        "baseline_model = SVC(kernel='linear', random_state=42)\n",
        "baseline_model.fit(X_train_tfidf, y_train)\n",
        "baseline_pred = baseline_model.predict(X_test_tfidf)\n",
        "baseline_f1 = f1_score(y_test, baseline_pred, average='macro')\n",
        "\n",
        "print(f\"Baseline Macro F1: {baseline_f1:.4f}\")\n",
        "print(f\"Baseline Accuracy: {accuracy_score(y_test, baseline_pred):.4f}\")\n",
        "\n",
        "# Per-class baseline performance\n",
        "baseline_f1_per_class = f1_score(y_test, baseline_pred, average=None)\n",
        "print(f\"\\nBaseline per-class F1:\")\n",
        "for i, rating in enumerate(sorted(np.unique(y_test))):\n",
        "    print(f\"  Rating {rating}: {baseline_f1_per_class[i]:.4f}\")\n",
        "\n",
        "# =============================================================================\n",
        "# TEST 1: CLASS WEIGHTS\n",
        "# =============================================================================\n",
        "\n",
        "print(f\"\\nüß™ TEST 1: Class-Weighted SVM...\")\n",
        "\n",
        "try:\n",
        "    # Calculate weights\n",
        "    classes = np.unique(y_train)\n",
        "    weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
        "    weight_dict = dict(zip(classes, weights))\n",
        "\n",
        "    print(f\"Class weights calculated:\")\n",
        "    for rating, weight in weight_dict.items():\n",
        "        print(f\"  Rating {rating}: {weight:.2f}\")\n",
        "\n",
        "    # Train weighted model\n",
        "    weighted_svm = SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
        "    weighted_svm.fit(X_train_tfidf, y_train)\n",
        "    weighted_pred = weighted_svm.predict(X_test_tfidf)\n",
        "    weighted_f1 = f1_score(y_test, weighted_pred, average='macro')\n",
        "\n",
        "    print(f\"‚úÖ Weighted SVM Macro F1: {weighted_f1:.4f}\")\n",
        "    print(f\"‚úÖ Improvement: {((weighted_f1 - baseline_f1)/baseline_f1)*100:+.1f}%\")\n",
        "\n",
        "    # Per-class performance\n",
        "    weighted_f1_per_class = f1_score(y_test, weighted_pred, average=None)\n",
        "    print(f\"\\nWeighted SVM per-class F1:\")\n",
        "    for i, rating in enumerate(sorted(np.unique(y_test))):\n",
        "        improvement = ((weighted_f1_per_class[i] - baseline_f1_per_class[i]) / baseline_f1_per_class[i]) * 100 if baseline_f1_per_class[i] > 0 else 0\n",
        "        print(f\"  Rating {rating}: {weighted_f1_per_class[i]:.4f} ({improvement:+.1f}%)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error in Test 1: {e}\")\n",
        "\n",
        "# =============================================================================\n",
        "# TEST 2: LOGISTIC REGRESSION WITH WEIGHTS\n",
        "# =============================================================================\n",
        "\n",
        "print(f\"\\nüß™ TEST 2: Weighted Logistic Regression...\")\n",
        "\n",
        "try:\n",
        "    weighted_lr = LogisticRegression(\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        max_iter=1000,\n",
        "        solver='liblinear'  # Better for small datasets\n",
        "    )\n",
        "    weighted_lr.fit(X_train_tfidf, y_train)\n",
        "    lr_pred = weighted_lr.predict(X_test_tfidf)\n",
        "    lr_f1 = f1_score(y_test, lr_pred, average='macro')\n",
        "\n",
        "    print(f\"‚úÖ Weighted Logistic Macro F1: {lr_f1:.4f}\")\n",
        "    print(f\"‚úÖ Improvement: {((lr_f1 - baseline_f1)/baseline_f1)*100:+.1f}%\")\n",
        "\n",
        "    # Per-class performance\n",
        "    lr_f1_per_class = f1_score(y_test, lr_pred, average=None)\n",
        "    print(f\"\\nWeighted Logistic per-class F1:\")\n",
        "    for i, rating in enumerate(sorted(np.unique(y_test))):\n",
        "        improvement = ((lr_f1_per_class[i] - baseline_f1_per_class[i]) / baseline_f1_per_class[i]) * 100 if baseline_f1_per_class[i] > 0 else 0\n",
        "        print(f\"  Rating {rating}: {lr_f1_per_class[i]:.4f} ({improvement:+.1f}%)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error in Test 2: {e}\")\n",
        "\n",
        "# =============================================================================\n",
        "# TEST 3: RANDOM FOREST WITH WEIGHTS\n",
        "# =============================================================================\n",
        "\n",
        "print(f\"\\nüß™ TEST 3: Weighted Random Forest...\")\n",
        "\n",
        "try:\n",
        "    weighted_rf = RandomForestClassifier(\n",
        "        class_weight='balanced',\n",
        "        n_estimators=50,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    weighted_rf.fit(X_train_tfidf, y_train)\n",
        "    rf_pred = weighted_rf.predict(X_test_tfidf)\n",
        "    rf_f1 = f1_score(y_test, rf_pred, average='macro')\n",
        "\n",
        "    print(f\"‚úÖ Weighted RF Macro F1: {rf_f1:.4f}\")\n",
        "    print(f\"‚úÖ Improvement: {((rf_f1 - baseline_f1)/baseline_f1)*100:+.1f}%\")\n",
        "\n",
        "    # Per-class performance\n",
        "    rf_f1_per_class = f1_score(y_test, rf_pred, average=None)\n",
        "    print(f\"\\nWeighted RF per-class F1:\")\n",
        "    for i, rating in enumerate(sorted(np.unique(y_test))):\n",
        "        improvement = ((rf_f1_per_class[i] - baseline_f1_per_class[i]) / baseline_f1_per_class[i]) * 100 if baseline_f1_per_class[i] > 0 else 0\n",
        "        print(f\"  Rating {rating}: {rf_f1_per_class[i]:.4f} ({improvement:+.1f}%)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error in Test 3: {e}\")\n",
        "\n",
        "# =============================================================================\n",
        "# TEST 4: SIMPLE OVERSAMPLING\n",
        "# =============================================================================\n",
        "\n",
        "print(f\"\\nüß™ TEST 4: Simple Oversampling...\")\n",
        "\n",
        "try:\n",
        "    # Find minority classes (1 and 2)\n",
        "    minority_mask_1 = y_train == 1\n",
        "    minority_mask_2 = y_train == 2\n",
        "\n",
        "    # Get minority samples\n",
        "    minority_reviews_1 = X_train[minority_mask_1]\n",
        "    minority_labels_1 = y_train[minority_mask_1]\n",
        "    minority_reviews_2 = X_train[minority_mask_2]\n",
        "    minority_labels_2 = y_train[minority_mask_2]\n",
        "\n",
        "    # Repeat minority samples 5 times\n",
        "    oversample_factor = 5\n",
        "\n",
        "    X_train_oversampled = pd.concat([\n",
        "        X_train,\n",
        "        pd.concat([minority_reviews_1] * oversample_factor),\n",
        "        pd.concat([minority_reviews_2] * oversample_factor)\n",
        "    ])\n",
        "\n",
        "    y_train_oversampled = pd.concat([\n",
        "        y_train,\n",
        "        pd.concat([minority_labels_1] * oversample_factor),\n",
        "        pd.concat([minority_labels_2] * oversample_factor)\n",
        "    ])\n",
        "\n",
        "    print(f\"Original training size: {len(X_train):,}\")\n",
        "    print(f\"Oversampled training size: {len(X_train_oversampled):,}\")\n",
        "\n",
        "    # Show new distribution\n",
        "    new_counts = y_train_oversampled.value_counts().sort_index()\n",
        "    print(f\"New distribution:\")\n",
        "    for rating, count in new_counts.items():\n",
        "        percentage = (count / len(y_train_oversampled)) * 100\n",
        "        print(f\"  Rating {rating}: {count:,} ({percentage:.1f}%)\")\n",
        "\n",
        "    # Extract features for oversampled data\n",
        "    X_train_oversampled_tfidf = vectorizer.transform(X_train_oversampled)\n",
        "\n",
        "    # Train model on oversampled data\n",
        "    oversample_svm = SVC(kernel='linear', random_state=42)\n",
        "    oversample_svm.fit(X_train_oversampled_tfidf, y_train_oversampled)\n",
        "    oversample_pred = oversample_svm.predict(X_test_tfidf)\n",
        "    oversample_f1 = f1_score(y_test, oversample_pred, average='macro')\n",
        "\n",
        "    print(f\"‚úÖ Oversampled SVM Macro F1: {oversample_f1:.4f}\")\n",
        "    print(f\"‚úÖ Improvement: {((oversample_f1 - baseline_f1)/baseline_f1)*100:+.1f}%\")\n",
        "\n",
        "    # Per-class performance\n",
        "    oversample_f1_per_class = f1_score(y_test, oversample_pred, average=None)\n",
        "    print(f\"\\nOversampled SVM per-class F1:\")\n",
        "    for i, rating in enumerate(sorted(np.unique(y_test))):\n",
        "        improvement = ((oversample_f1_per_class[i] - baseline_f1_per_class[i]) / baseline_f1_per_class[i]) * 100 if baseline_f1_per_class[i] > 0 else 0\n",
        "        print(f\"  Rating {rating}: {oversample_f1_per_class[i]:.4f} ({improvement:+.1f}%)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error in Test 4: {e}\")\n",
        "\n",
        "# =============================================================================\n",
        "# SUMMARY\n",
        "# =============================================================================\n",
        "\n",
        "print(f\"\\nüìä SUMMARY OF ALL TECHNIQUES:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Collect all results\n",
        "all_techniques = ['Baseline SVM']\n",
        "all_f1_scores = [baseline_f1]\n",
        "\n",
        "if 'weighted_f1' in locals():\n",
        "    all_techniques.append('Weighted SVM')\n",
        "    all_f1_scores.append(weighted_f1)\n",
        "\n",
        "if 'lr_f1' in locals():\n",
        "    all_techniques.append('Weighted Logistic')\n",
        "    all_f1_scores.append(lr_f1)\n",
        "\n",
        "if 'rf_f1' in locals():\n",
        "    all_techniques.append('Weighted Random Forest')\n",
        "    all_f1_scores.append(rf_f1)\n",
        "\n",
        "if 'oversample_f1' in locals():\n",
        "    all_techniques.append('Oversampled SVM')\n",
        "    all_f1_scores.append(oversample_f1)\n",
        "\n",
        "# Find best\n",
        "best_idx = np.argmax(all_f1_scores)\n",
        "best_technique = all_techniques[best_idx]\n",
        "best_f1 = all_f1_scores[best_idx]\n",
        "\n",
        "print(f\"üèÜ BEST TECHNIQUE: {best_technique}\")\n",
        "print(f\"üìà Best Macro F1: {best_f1:.4f}\")\n",
        "print(f\"üìà Improvement over baseline: {((best_f1 - baseline_f1)/baseline_f1)*100:+.1f}%\")\n",
        "\n",
        "print(f\"\\nüéØ All Results:\")\n",
        "for i, (technique, f1) in enumerate(zip(all_techniques, all_f1_scores)):\n",
        "    improvement = ((f1 - baseline_f1)/baseline_f1)*100 if technique != 'Baseline SVM' else 0\n",
        "    print(f\"  {technique}: {f1:.4f} ({improvement:+.1f}%)\")\n",
        "\n",
        "print(f\"\\n‚úÖ DEBUG COMPLETE!\")\n",
        "if best_f1 > baseline_f1:\n",
        "    print(f\"üí° SUCCESS: Found improvement with {best_technique}!\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Need to investigate further - trying different approaches...\")"
      ]
    }
  ]
}