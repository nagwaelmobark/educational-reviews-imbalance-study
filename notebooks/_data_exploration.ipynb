# Educational Reviews Imbalance Study - Data Exploration
# Notebook 01: Initial Data Analysis and Visualization

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# Set visualization style
plt.style.use('default')
sns.set_palette("husl")

print("üéØ Educational Reviews Imbalance Study")
print("=" * 50)
print("üìä Notebook 01: Data Exploration and Analysis")
print("=" * 50)

# =============================================================================
# 1. DATA LOADING AND BASIC INFO
# =============================================================================

print("\n1Ô∏è‚É£ LOADING DATA...")
try:
    # Load the dataset
    df = pd.read_csv('../data/raw/reviews.csv')
    print(f"‚úÖ Data loaded successfully!")
    print(f"üìä Dataset shape: {df.shape}")
    print(f"üîπ Rows: {df.shape[0]:,}")
    print(f"üîπ Columns: {df.shape[1]:,}")
except Exception as e:
    print(f"‚ùå Error loading data: {e}")

# Basic dataset info
print("\nüìã DATASET INFO:")
print("-" * 30)
print(df.info())

# Check for missing values
print("\nüîç MISSING VALUES:")
print("-" * 20)
missing_vals = df.isnull().sum()
print(missing_vals)
print(f"Total missing values: {missing_vals.sum()}")

# =============================================================================
# 2. CLASS DISTRIBUTION ANALYSIS
# =============================================================================

print("\n2Ô∏è‚É£ CLASS DISTRIBUTION ANALYSIS...")
print("=" * 40)

# Count each rating
label_counts = df['Label'].value_counts().sort_index()
total_samples = len(df)

print("üìä Class Distribution:")
print("-" * 25)
for label in sorted(df['Label'].unique()):
    count = label_counts[label]
    percentage = (count / total_samples) * 100
    stars = "‚≠ê" * label
    print(f"{stars} ({label}): {count:,} samples ({percentage:.2f}%)")

# Calculate imbalance ratio
max_class = label_counts.max()
min_class = label_counts.min()
imbalance_ratio = max_class / min_class
print(f"\n‚öñÔ∏è Imbalance Ratio: {imbalance_ratio:.1f}:1")
print(f"üî∏ Majority class (5): {label_counts[5]:,} samples")
print(f"üî∏ Minority class (1): {label_counts[1]:,} samples")

# =============================================================================
# 3. TEXT ANALYSIS
# =============================================================================

print("\n3Ô∏è‚É£ TEXT CHARACTERISTICS ANALYSIS...")
print("=" * 40)

# Calculate text lengths
df['text_length'] = df['Review'].astype(str).str.len()
df['word_count'] = df['Review'].astype(str).str.split().str.len()

print("üìù Text Statistics:")
print("-" * 20)
print(f"Average text length: {df['text_length'].mean():.1f} characters")
print(f"Average word count: {df['word_count'].mean():.1f} words")
print(f"Shortest review: {df['text_length'].min()} characters")
print(f"Longest review: {df['text_length'].max()} characters")

# Text length by rating
print("\nüìä Text Length by Rating:")
print("-" * 30)
for rating in sorted(df['Label'].unique()):
    subset = df[df['Label'] == rating]
    avg_length = subset['text_length'].mean()
    avg_words = subset['word_count'].mean()
    print(f"Rating {rating}: {avg_length:.1f} chars, {avg_words:.1f} words")

# =============================================================================
# 4. SAMPLE REVIEWS FOR EACH RATING
# =============================================================================

print("\n4Ô∏è‚É£ SAMPLE REVIEWS BY RATING...")
print("=" * 35)

for rating in sorted(df['Label'].unique()):
    print(f"\n‚≠ê" * rating + f" RATING {rating} EXAMPLES:")
    print("-" * 40)
    samples = df[df['Label'] == rating]['Review'].head(3)
    for i, review in enumerate(samples, 1):
        # Truncate long reviews for display
        display_text = review[:150] + "..." if len(review) > 150 else review
        print(f"{i}. {display_text}")

# =============================================================================
# 5. VISUALIZATIONS
# =============================================================================

print("\n5Ô∏è‚É£ CREATING VISUALIZATIONS...")
print("=" * 30)

# Create figure with subplots
fig, axes = plt.subplots(2, 2, figsize=(15, 12))
fig.suptitle('Educational Reviews Dataset Analysis', fontsize=16, fontweight='bold')

# 1. Class Distribution Bar Plot
ax1 = axes[0, 0]
bars = ax1.bar(label_counts.index, label_counts.values, 
               color=['#ff4444', '#ff8800', '#ffbb00', '#88bb00', '#00bb44'])
ax1.set_title('Class Distribution', fontweight='bold')
ax1.set_xlabel('Rating')
ax1.set_ylabel('Number of Reviews')
ax1.set_xticks(range(1, 6))
ax1.set_xticklabels([f'{i}‚≠ê' for i in range(1, 6)])

# Add value labels on bars
for bar, count in zip(bars, label_counts.values):
    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1000,
             f'{count:,}', ha='center', va='bottom', fontweight='bold')

# 2. Class Distribution Pie Chart
ax2 = axes[0, 1]
colors = ['#ff4444', '#ff8800', '#ffbb00', '#88bb00', '#00bb44']
wedges, texts, autotexts = ax2.pie(label_counts.values, labels=[f'{i}‚≠ê' for i in range(1, 6)], 
                                  autopct='%1.1f%%', colors=colors, startangle=90)
ax2.set_title('Rating Distribution', fontweight='bold')

# Make percentage text bold
for autotext in autotexts:
    autotext.set_color('white')
    autotext.set_fontweight('bold')

# 3. Text Length Distribution
ax3 = axes[1, 0]
ax3.hist(df['text_length'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')
ax3.set_title('Text Length Distribution', fontweight='bold')
ax3.set_xlabel('Character Count')
ax3.set_ylabel('Frequency')
ax3.axvline(df['text_length'].mean(), color='red', linestyle='--', 
           label=f'Mean: {df["text_length"].mean():.0f}')
ax3.legend()

# 4. Average Text Length by Rating
ax4 = axes[1, 1]
avg_lengths = df.groupby('Label')['text_length'].mean()
bars = ax4.bar(avg_lengths.index, avg_lengths.values, 
               color=['#ff4444', '#ff8800', '#ffbb00', '#88bb00', '#00bb44'])
ax4.set_title('Average Text Length by Rating', fontweight='bold')
ax4.set_xlabel('Rating')
ax4.set_ylabel('Average Character Count')
ax4.set_xticks(range(1, 6))
ax4.set_xticklabels([f'{i}‚≠ê' for i in range(1, 6)])

# Add value labels
for bar, length in zip(bars, avg_lengths.values):
    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10,
             f'{length:.0f}', ha='center', va='bottom', fontweight='bold')

plt.tight_layout()
plt.show()

# =============================================================================
# 6. IMBALANCE ANALYSIS SUMMARY
# =============================================================================

print("\n6Ô∏è‚É£ IMBALANCE ANALYSIS SUMMARY")
print("=" * 40)

# Calculate imbalance metrics
positive_samples = len(df[df['Label'].isin([4, 5])])  # Positive (4, 5)
negative_samples = len(df[df['Label'].isin([1, 2])])  # Negative (1, 2)
neutral_samples = len(df[df['Label'] == 3])          # Neutral (3)

positive_pct = (positive_samples / total_samples) * 100
negative_pct = (negative_samples / total_samples) * 100
neutral_pct = (neutral_samples / total_samples) * 100

print("üéØ SENTIMENT DISTRIBUTION:")
print("-" * 30)
print(f"üòä Positive (4-5‚≠ê): {positive_samples:,} ({positive_pct:.1f}%)")
print(f"üòê Neutral (3‚≠ê):    {neutral_samples:,} ({neutral_pct:.1f}%)")
print(f"üòû Negative (1-2‚≠ê):  {negative_samples:,} ({negative_pct:.1f}%)")

print(f"\n‚ö†Ô∏è IMBALANCE CHALLENGES:")
print("-" * 30)
print(f"‚Ä¢ Positive:Negative ratio = {positive_samples/negative_samples:.1f}:1")
print(f"‚Ä¢ Majority class dominance: {label_counts.max()/total_samples*100:.1f}%")
print(f"‚Ä¢ Minority classes total: {(label_counts[1] + label_counts[2])/total_samples*100:.1f}%")

# =============================================================================
# 7. DATA QUALITY CHECK
# =============================================================================

print("\n7Ô∏è‚É£ DATA QUALITY ASSESSMENT")
print("=" * 35)

# Check for duplicates
duplicates = df.duplicated().sum()
print(f"üîç Duplicate rows: {duplicates}")

# Check for very short/long reviews
very_short = len(df[df['text_length'] < 10])
very_long = len(df[df['text_length'] > 1000])
print(f"üìè Very short reviews (<10 chars): {very_short}")
print(f"üìè Very long reviews (>1000 chars): {very_long}")

# Check for empty reviews
empty_reviews = df['Review'].isna().sum() + (df['Review'] == '').sum()
print(f"üìù Empty reviews: {empty_reviews}")

print(f"\n‚úÖ DATA QUALITY SCORE: {((total_samples - duplicates - empty_reviews)/total_samples)*100:.1f}%")

# =============================================================================
# 8. NEXT STEPS RECOMMENDATIONS
# =============================================================================

print("\n8Ô∏è‚É£ NEXT STEPS FOR IMBALANCE HANDLING")
print("=" * 45)

print("üéØ RECOMMENDED TECHNIQUES TO TEST:")
print("-" * 35)
print("1. üîÑ SMOTE (Synthetic Minority Oversampling)")
print("2. ‚öñÔ∏è Cost-Sensitive Learning with class weights")
print("3. üéØ Threshold Moving optimization")
print("4. üå≥ Balanced Random Forest")
print("5. üîÄ Hybrid: SMOTE + Tomek Links")

print(f"\nüìä BASELINE METRICS TO ESTABLISH:")
print("-" * 35)
print("‚Ä¢ Overall Accuracy")
print("‚Ä¢ Per-class Precision, Recall, F1-score")
print("‚Ä¢ Macro and Micro averages")
print("‚Ä¢ Confusion Matrix analysis")

print(f"\nüöÄ READY FOR BASELINE EXPERIMENTS!")
print("   Next notebook: 02_baseline_experiments.ipynb")
print("=" * 50)
